{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q40o1FaUBl8g"
   },
   "source": [
    "### Data Science Workflow Assignment\n",
    "\n",
    "The objective of this notebook is to provide a high level overview of an exemplar data science workflow using actual data.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "Read and step through the noteook and answer the question at the end of the noteboo.\n",
    "\n",
    "References:  \n",
    "Joe Blitztein, CS 109 Data Science     \n",
    "https://github.com/cs109/2015\n",
    "\n",
    "Development Workflows for Data Scientists     \n",
    "https://resources.github.com/downloads/development-workflows-data-scientists.pdf\n",
    "\n",
    "Top Ranked English Movies Of This Decade     \n",
    "https://www.kaggle.com/saipranava/top-ranked-enlglish-movies-of-this-decade/data#IMDB.csv\n",
    "\n",
    "Aakash Tandel, A Data Science Workflow   \n",
    "https://towardsdatascience.com/a-data-science-workflow-26c3f05a010e\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z9YPeLh6Bl8i"
   },
   "source": [
    "### Introduction\n",
    "\n",
    "There is no specific step-by-step process for solving all data science problems. The process needs to be adjusted with every new problem and dataset. We do however see similar procedural steps in most projects. \n",
    "\n",
    "For the purposes of this overview, we will following the Data Science Workflow from Joe Blitztein, CS 109 Data Science.\n",
    "\n",
    "<img src=\"data_science_workflow.png\" width=\"400px\"/>\n",
    "\n",
    "Source: Joe Blitztein, CS 109 Data Science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SzWLvT05Bl8j"
   },
   "source": [
    "### Data Science Workflow\n",
    "\n",
    "1.\tAsk an interesting question \n",
    "2.\tGet the data \n",
    "3.\tExplore (and clean the data)\n",
    "5.\tModel the data \n",
    "6.\tCommunicate and visualize the results \n",
    "8.  Conclusion\n",
    "9.  Resources\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "op_A6aZ4Bl8k"
   },
   "source": [
    "### 1) Ask an interesting question \n",
    "\n",
    "What is the scientific goal? How can we use the data? What do we want to predict or estimate?\n",
    "\n",
    "For this exercise, we are going to analyze the highest ranked movies on IMDB.com. \n",
    "\n",
    "The question: Can we predict IMDB movie ratings based on features like budget, runtime, and votes on the website?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ACC8U-ZTBl8l"
   },
   "source": [
    "### 2) Get the Data\n",
    "\n",
    "How was the data sampled? What data is relevant? Are there any privacy issues?\n",
    "\n",
    "Data can come from a variety of sources. CSV (comma separated value) text files, running SQL queries on a database, or various sources on the Internet. \n",
    "\n",
    "It is common to use the Python library, `Pandas`, to import data. Pandas represents the data in a tabular data structure called a dataframe.\n",
    "\n",
    "Once the data is in a dataframe, we can more easily clean, analyze and model the data.\n",
    "\n",
    "We will be using a Kaggle dataset titled \"Top Ranked English Movies of this Decade.\" The data is available in a CSV file. \n",
    "\n",
    "https://www.kaggle.com/saipranava/top-ranked-enlglish-movies-of-this-decade/data\n",
    "\n",
    "https://www.kaggle.com/saipranava/top-ranked-enlglish-movies-of-this-decade/download/SD2LNx0Z2MES3z3L53qQ%2Fversions%2FPSiePnuWqTJZrCan4Qua%2Ffiles%2FIMDB.csv?datasetVersionNumber=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_iGvHO47Bl8m"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv('https://tf-assets-prod.s3.amazonaws.com/tf-curric/data-science/top-ranked-enlglish-movies-of-this-decade/IMDB.csv', index_col=0, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4UtFvq6bBl8p"
   },
   "source": [
    "### 3) Explore (and clean) the data\n",
    "\n",
    "- Examine and clean the data     \n",
    "\n",
    "- Plot the data\n",
    "\n",
    "- Analyze the data\n",
    "\n",
    "Now that the data is in a Pandas dataframe, we can determine its size and inspect the first few rows of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "blqkqB8sBl8q"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "97NP0w5uBl8t"
   },
   "source": [
    "The shape attribute tells us there are 119 rows and 54 columns or attributes. Which is a very small dataset, but useful for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-X1-jfm1Bl8v"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zm0SzbCiBl8z"
   },
   "source": [
    "The target variable we are trying to predict is in the `Rating` column. \n",
    "\n",
    "The features or input variables we are going to use are: `MetaCritic`, `Budget`, `Runtime`, `VotesUS`, `VotesnUS`, and `TotalVotes`. We will remove all of the other columns from our analysis.\n",
    "\n",
    "*Note: There are several methods we will learn later in the course for selecting the most relevant features for building a production model.*\n",
    "\n",
    "The code below creates a new dataframe with a subset of the columns we need and lists the first 10 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7hovIhSiBl80"
   },
   "outputs": [],
   "source": [
    "df = df[['Title', 'Rating', 'TotalVotes', 'MetaCritic', 'Budget', 'Runtime', 'VotesUS', 'VotesnUS']]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "34LIpzYQBl83"
   },
   "source": [
    "Missing and null values are a common problem. For example, the `NaN` value in the `MetaCritic` column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2SILa8W3Bl84"
   },
   "outputs": [],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bIiP_wnjBl87"
   },
   "source": [
    "We may not have captures all of the missing values with this summary.\n",
    "\n",
    "We can sum the missing values per column as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R33UhP0jBl88"
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MDOxiBwvBl9A"
   },
   "source": [
    "Here we can see missing values for `Runtime` and `VotesnUS.`\n",
    "\n",
    "Strategies for correcting missing values include removing those rows or *imputing* some value. Missing data imputation invovles replacing missing or null values using some strategy. Strategies include the most frequently occuring value, the mean, etc.\n",
    "\n",
    "For now, we will just drop these rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f2agdwVmBl9B"
   },
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gwvLktZqBl9E"
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v28hpuH2Bl9H"
   },
   "source": [
    "Tada!\n",
    "\n",
    "Another important check in the dataset are the data types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5_Eh532BBl9I",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jQxUPiL_Bl9K"
   },
   "source": [
    "Notice how `TotalVotes` , `Budget`,  `Runtime`, `VotesUS`, and `VotesnUS` are of type *object*. This is due to these fields including non-numeric characters like ',' and '$.' \n",
    "\n",
    "We need to convert these to numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yx4YROWpBl9L"
   },
   "outputs": [],
   "source": [
    "df.TotalVotes = df.TotalVotes.str.replace(',', '')\n",
    "df.TotalVotes = df.TotalVotes.astype(int)\n",
    "df.TotalVotes.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pdzXEODUBl9N"
   },
   "source": [
    "For some rows, `Budget` also contains some embedded text. We will just remove these rows. Another option could use regular expressions to try to extract the actual value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1zT8qFPoBl9O"
   },
   "outputs": [],
   "source": [
    "df = df[(df.Budget.str.contains(\"Opening\") == False) & \n",
    "        (df.Budget.str.contains(\"Path√©\") == False) &\n",
    "        (df.Budget.str.contains(\"Production\") == False)]\n",
    "df.Budget = df.Budget.str.replace('[^\\x00-\\x7F]','')\n",
    "df.Budget = df.Budget.str.replace(',', '')\n",
    "df.Budget = df.Budget.str.replace('$', '')\n",
    "df.Budget = df.Budget.astype(int)\n",
    "df.Budget.dtype "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dgzXIE8hBl9R"
   },
   "source": [
    "For `Runtime` we will use a regular expression to extract the numeric value for that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yZallsZIBl9T"
   },
   "outputs": [],
   "source": [
    "df.Runtime = df.Runtime.str.extract('(\\d+)', expand=False)\n",
    "df.Runtime = df.Runtime.astype(int)\n",
    "df.Runtime.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h_k8KippBl9W"
   },
   "source": [
    "Finally, we need to convert `VotesnUS` and `VotesUS.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vQhXhkQlBl9W"
   },
   "outputs": [],
   "source": [
    "df.VotesnUS = df.VotesnUS.astype(float)\n",
    "print( df.VotesnUS.dtype )\n",
    "df.VotesUS = df.VotesUS.astype(float)\n",
    "print( df.VotesUS.dtype )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wp9kFM_TBl9Z"
   },
   "source": [
    "Our dataset is now ready for further exploratory data analysis. A good start is always to review the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G0Isqp_EBl9a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5NYYjoSzBl9c"
   },
   "source": [
    "We can also gett a quick look at the distribution of the data with the `describe()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "muUH2Fn_Bl9d"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lSWSzBYlBl9h"
   },
   "source": [
    "Just looking numbers or statistical summaries can be dificult to comprehend.\n",
    "\n",
    "Plotting allows us to visually inspect and gain better insights into our data. There are many options includimg histograms, scatter plots, correlation plots, box plots, etc. The best options will depend on our data and the problem we are trying to solve.\n",
    "\n",
    "`Matplotlib` and `Pandas` (which embeds Matplotlib in its functionality) provide handy plotig tools. \n",
    "\n",
    "Throughout this analysis process, we may discover outlier or other irregularities in our data that we may need to be cleaned. Real world data tends to be pretty messy.\n",
    "\n",
    "For this example, below Pandas to create a scatter matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hbP1gGg3Bl9l"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.plotting.scatter_matrix(df, figsize=(20,20))\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L8T7F55BBl9r"
   },
   "source": [
    "From the above plot, we're most intresting in looking for patterns or correlation between the target or dependent variable `Rating` and the other indepdent variables.\n",
    "\n",
    "Another important step that may be necessary is *feature engineering* which involves transforming exising features or creating new features. We will skip feature engineering for now and revisit this later in the course.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "icXerJ6jBl9s"
   },
   "source": [
    "### Model the data\n",
    "\n",
    "The type of model we use will depend on our type of problem. \n",
    "\n",
    "If our data has a value that we are trying to predict, this is a *supervised learning problem*. If the value we are predicting is a label or category, we call this a classification problem. If we are trying to predict a number, like `Rating` (our case), we call this a regression problem.\n",
    "\n",
    "Another important category or problems are *unsupervised*. In this case, we either do not have a value we are trying to predict or we are just trying to better understand the association between variable in our data.\n",
    "\n",
    "For our example, we are going to be using regression (supervised learning) to predict the IMDB `Rating` from `TotalVotes`, `MetaCritic`, `Budget`, `Runtime`, `VotesUS`, and `VotesnUS.`\n",
    "\n",
    "In general, it is a good idea to first create a *baseline* model. A baseline model is usually a simple, linear model that allows us to gain futher insight into our problem. For our example, we will use *linear regression* which is available in the *Scikit-Learn* library.\n",
    "\n",
    "**Scikit-Learn** is a machine learning package for Python that can be used for a variety of tasks. \n",
    "\n",
    "When building a model, it is important to hold out some data for training, called a *train-test-split* to prevent overfitting of our model. Overfitting is when the model fits the training data too closely, and does not do a good job predicting values for examples not included in the training data. I.e., the model does not generalize well to new examples. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "30_2UpQcBl9t"
   },
   "source": [
    "First, we need to separate our feature variables `X` (a matrix) from our target variable `y` for `Scikit-Learn.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VvnZqgHhBl9v"
   },
   "outputs": [],
   "source": [
    "y = df.Rating\n",
    "X = df[['TotalVotes', 'MetaCritic', 'Budget', 'Runtime', 'VotesUS', 'VotesnUS']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SKK9yQ7-Bl9y"
   },
   "source": [
    "Next, we will scale values to between $0$ and $1$ using `MinMaxScaler.` Scaling values helps learning optimization algorithms like `gradient descent` converge on the appropriate model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E4Vr7kfABl90",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QFhOvDCzBl95"
   },
   "outputs": [],
   "source": [
    "Xs = MinMaxScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HrmJPjWYBl98"
   },
   "source": [
    "Create the train test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DGqpwxYYBl99"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ovBfoEjBl9_"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Xs, y, test_size=0.2)\n",
    "print (X_train.shape, y_train.shape)\n",
    "print (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oOiEbm6UBl-D"
   },
   "source": [
    "We are now ready to train a baseline model where we *fit* our model to the training data. \n",
    "\n",
    "Then we test our model by having it *predict* `y` values for our `X_test` data. We can then *evaluate* the performance of the model by comparing the predicted values for *y* values to  the actual *y* values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "unT4EikmBl-D"
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j9-qMeHnBl-H"
   },
   "outputs": [],
   "source": [
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(X_train, y_train)\n",
    "predictions = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GTeVbCJeBl-L"
   },
   "source": [
    "Below we generate a scatter plot of Predicted versus Actual values of `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7-ySFiOaBl-M"
   },
   "outputs": [],
   "source": [
    "plt.scatter(y_test, predictions)\n",
    "plt.xlabel('Actual y')\n",
    "plt.ylabel('Predicted y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PKWx7Y1OBl-U"
   },
   "source": [
    "And here we calculate the score using `R-squared`, which is the default metric used by `Scikit-Learn` for regression problems.\n",
    "\n",
    "Basically, 1R-squared1, is a goodness-of-fit metric. It is the percentage of variation in our `y` variable explained by our model. A value close to 1 is good!\n",
    "\n",
    "Other common evaluation metrics for regression include `Root Mean Squared Error` and `Adjusted R-squared`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fAUEqv2PBl-W"
   },
   "outputs": [],
   "source": [
    "print ('Score:', model.score(X_test, y_test))  # R-squared is the default metric used by Sklearn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uhNhoZG3Bl-Y"
   },
   "source": [
    "$0.95$ $R^2$ is a very good number.\n",
    "\n",
    "At this step, we would most likely futher explore the validity of our results, and evaluate other machine learning algorithms and explore feature engineering techniques to see of we can improve our results. \n",
    "\n",
    "One area of concern is collinearity. Collinearrity is when you have features that are very similar and give the same information about the target variable. For example, temperature in Celsius and Fahrenheit. The features `VotesUS` and `VotesnUS` could highly correlated. This could help explain the high $R^2$ value. We may want to consider using Adjuarted $R^2$ or other evalution metrics. A correlation plot would help explore this further. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aN2PGRhLBl-Z"
   },
   "source": [
    "Beta coefficients are the parameters learned by our linear model. For linear regression, they represent the change in the targe value of a unit change for each input variable holding all other variables constant.\n",
    "\n",
    "We see that `VotesnUS.` had the largest postive impact on our target variable.\n",
    "\n",
    "Other Python packages like `Statsmodels` provide regression coefficients and their associated `p-values` which lets us know if these coefficient are statisticall significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vMXoK9RSBl-Z"
   },
   "outputs": [],
   "source": [
    "lm.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n3NzcR13Bl-c"
   },
   "source": [
    "We will move on to the final step in our process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6PZ8GR73Bl-d"
   },
   "source": [
    "### Communicate and visualize the results\n",
    "\n",
    "Finally, you need to communicate your results. The beauty of using notebooks is that they provide a great way to integrate documentaion, methods, and results.\n",
    "\n",
    "The best form of communication will depend on your problem and your target audience. For each of the following audiences, identify aspects of this study that would be most relevant:\n",
    "\n",
    "- Data Scientist\n",
    "\n",
    "- Software/data engineer\n",
    "\n",
    "- Marketing manager\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "AWAljaWDBl-d"
   },
   "source": [
    "Answer:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qIeAVDn1Bl-e"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "02_02_DataScienceWorkflow_assign.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
